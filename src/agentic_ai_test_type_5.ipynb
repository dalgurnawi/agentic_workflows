{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3a3bcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "import psycopg2\n",
    "import ollama\n",
    "import pandas as pd\n",
    "from IPython.display import Image, Markdown, display\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import urllib.parse\n",
    "from langchain.messages import AIMessage\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_deepseek import ChatDeepSeek\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain.agents import create_agent\n",
    "from agentic_ai_tools import AccessAccountsReceivable, AccessPayments\n",
    "import datetime as dt\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from langchain.agents.structured_output import ToolStrategy\n",
    "from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "from typing import Union, List, Dict\n",
    "import datetime\n",
    "from datetime import date \n",
    "from sqlalchemy import create_engine\n",
    "import csv\n",
    "import ast\n",
    "from typing import Optional\n",
    "import signal\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7d3856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain API KEY\n",
    "LANGSMITH_API_KEY=os.getenv('LANGSMITH_API_KEY')\n",
    "LANGSMITH_ENDPOINT=os.getenv('LANGSMITH_ENDPOINT')\n",
    "# DATABASE Connection settings\n",
    "DB_NAME=os.getenv('DB_NAME')\n",
    "USERNAME=os.getenv('USERNAME')\n",
    "PASSWORD=urllib.parse.quote(os.getenv('PASSWORD'))\n",
    "HOSTNAME=os.getenv('HOSTNAME')\n",
    "PORT=os.getenv('PORT')\n",
    "x = datetime.datetime.now()\n",
    "\n",
    "# Creating conneciton to database\n",
    "\n",
    "engine = create_engine(f'postgresql+psycopg2://{USERNAME}:{PASSWORD}@{HOSTNAME}/{DB_NAME}')\n",
    "#conn = psycopg2.connect(f\"dbname={DB_NAME} user={USERNAME} password={PASSWORD}\")\n",
    "accounts_receivables = pd.read_sql(\"SELECT * FROM accounts_receivable\", engine)\n",
    "payments= pd.read_sql(\"SELECT * FROM payments\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cf0171",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TimeoutException(Exception):   # Custom exception class\n",
    "    pass\n",
    "\n",
    "def timeout_handler(signum, frame):   # Custom signal handler\n",
    "    raise TimeoutException\n",
    "\n",
    "# Change the behavior of SIGALRM\n",
    "signal.signal(signal.SIGALRM, timeout_handler)\n",
    "\n",
    "# Add memory to your agent to maintain state across interactions. This allows the agent to remember previous conversations and context.\n",
    "checkpointer = InMemorySaver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00636942",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context():\n",
    "    \"\"\"Custom runtime context schema.\"\"\"\n",
    "    user_id: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2352fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Invoice(BaseModel):\n",
    "    invoice_number: Optional[int] = None\n",
    "    date: Optional[str] = None\n",
    "    customer_name: Optional[str] = None\n",
    "    customer_number: Optional[int] = None\n",
    "    amount: Optional[float] = None\n",
    "    due_date: Optional[str] = None\n",
    "    payment: Optional[float]= None\n",
    "    payment_date: Optional[str] = None\n",
    "    payment_id: Optional[int] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e09cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt =\"\"\"\n",
    "You are a senior accountant responsible for accounts receivable reconciliation.\n",
    "\n",
    "Rules:\n",
    "- When reconciliation or invoice updates are requested, you determine whether the payment is related to the invoice.\n",
    "- Never ask the user follow-up questions.\n",
    "- Do not explain your reasoning.\n",
    "- Do not return stringified data.\n",
    "- Do not return different structured data.\n",
    "- DO NOT nest the payments data into the updated accounts receivable information.\n",
    "\n",
    "Output requirements:\n",
    "- Return ONLY a Python dictionary.\n",
    "- The dictionary must represent the UPDATED accounts receivable.\n",
    "- Do not wrap the output in text, markdown, or code fences.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4011ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"qwen3:8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc12479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOllama(\n",
    "    model=llm_model,\n",
    "    temperature=0,\n",
    "    disable_streaming=True\n",
    "    #format=\"json\", # Enforce JSON Schema\n",
    "    #num_gpu=1\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "849e5561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_gen(dataframe):\n",
    "    for _, row in dataframe.iterrows():\n",
    "        yield str(row.to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af60a551",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_ar = row_gen(accounts_receivables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ef1fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_p= row_gen(payments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "648d53b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_eval_with_dates(string_data):\n",
    "    \"\"\"\n",
    "    Safely evaluate a string containing datetime objects and escaped quotes.\n",
    "    Converts datetime.date() calls to ISO format strings and fixes escaping.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    from datetime import date\n",
    "    \n",
    "    # First, fix escaped quotes - replace \\' with just '\n",
    "    # ast.literal_eval expects proper Python string literals\n",
    "    cleaned = string_data.replace(\"\\\\'\", \"'\")\n",
    "    \n",
    "    # Replace datetime.date(year, month, day) with ISO format strings\n",
    "    pattern = r'datetime\\.date\\((\\d+),\\s*(\\d+),\\s*(\\d+)\\)'\n",
    "    \n",
    "    def replace_date(match):\n",
    "        year, month, day = match.groups()\n",
    "        try:\n",
    "            d = date(int(year), int(month), int(day))\n",
    "            return f'\"{d.isoformat()}\"'\n",
    "        except ValueError:\n",
    "            return match.group(0)  # Return original if invalid date\n",
    "    \n",
    "    cleaned = re.sub(pattern, replace_date, cleaned)\n",
    "    \n",
    "    # Now use ast.literal_eval on the cleaned string\n",
    "    return ast.literal_eval(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b5a2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_log(model, error_message, ar_row_affected, p_row_affected):\n",
    "    x = datetime.datetime.now()\n",
    "    log_file = Path(f\"updated_ar_error_log_{model}_run_{x.day}-{x.month}-{x.year}.csv\")\n",
    "    log_file.touch(exist_ok=True)\n",
    "    f = open(log_file, 'w')\n",
    "    f.write(f\"Time: {x.hour}:{x.minute}\\nError message: {error_message}\\nAR Row affected: {ar_row_affected}\\nAR Datatype {type(ar_row_affected)}\\nPayment Row affected: {p_row_affected})\\nPayment Datatype {type(p_row_affected)}\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a93db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_based_checker(accounts_receivable, payments, generator_ar, generator_p):\n",
    "    \"\"\" Match apyments to accounts receivables and update AR records in an iterative manner\n",
    "        Args:\n",
    "            accounts_receivable: DataFrame of AR invoices\n",
    "            payments: DataFrame of payments\n",
    "            generator_ar: Method to return the next row of AR as a dictionary\n",
    "            generator_p: Method to return the next row of payments as a dictionary\n",
    "            Checkpointer: Checkpointer for the agent.\n",
    "        \n",
    "        Returns:\n",
    "            DataFrame: Updated accounts receivable records\n",
    "    \"\"\"\n",
    "    updated_ar = pd.DataFrame(columns=accounts_receivable.columns)\n",
    "    counter = 1100\n",
    "    #print(f\"Empty DF: {updated_ar}\")\n",
    "    for i in range(len(accounts_receivable)+1):\n",
    "        print(f\"Processing Invoice Nr: {i+1}/ {len(accounts_receivable)}\")\n",
    "        \n",
    "        # Get next AR row\n",
    "        try:\n",
    "            row_ar = next(generator_ar)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        \n",
    "        if row_ar is None:\n",
    "            break\n",
    "\n",
    "        is_match = False\n",
    "        \n",
    "        generator_p= row_gen(payments) # Recreate the payments generator, so that we do not run into a Stopiteration Error\n",
    "        # Stop iteration error is raised when a generator is exhausted and will have to be created again\n",
    "        \n",
    "        for j in tqdm(range(len(payments)), desc=f\"Matching payments for invoice {i+1}\"):\n",
    "            try:\n",
    "                row_p = next(generator_p)\n",
    "            except StopIteration:\n",
    "                break\n",
    "\n",
    "            if row_p is None:\n",
    "                continue\n",
    "            # Run agent\n",
    "            #`thread_id` is a unique identifier for a given conversation\n",
    "            config = {\"configurable\": {\"thread_id\": f\"{counter}\"}}\n",
    "            # Create the agent with default parameters\n",
    "            agent = create_agent(model=model, system_prompt=prompt, response_format=Invoice)\n",
    "            \n",
    "            # Start signal timer to kill the process if it hangs longer than 5 mins\n",
    "            signal.alarm(900)\n",
    "\n",
    "            try:\n",
    "            \n",
    "                # Ask the agent a question\n",
    "                response = agent.invoke({\"messages\": [{\"role\": \"user\", \n",
    "                                \"content\": f\"\"\"\n",
    "                You have been given an accounts receivable invoice {row_ar} and a received payment {row_p}. Assess whether the payment relates to the invoice. \n",
    "                If there is no match, return an empty dictionary. If it does, UPDATE the invoice data with relevant payment information and return \n",
    "                the updated record as a dictionary with all invoice fields. Do not create any new columns for accounts receivables. Return the updated accounts receivables data as\n",
    "                a dictionary with no other additional text.\n",
    "                \"\"\"}]},    config=config,\n",
    "                    context=Context())\n",
    "            \n",
    "            except TimeoutException as e:\n",
    "                error_log(model=llm_model, error_message=e, ar_row_affected=row_ar, p_row_affected=row_p)\n",
    "                continue # Continue the loop if function takes longer than 5 mins\n",
    "\n",
    "            else:\n",
    "                #Reset the alarm\n",
    "                signal.alarm(0)\n",
    "\n",
    "            counter +=1\n",
    "            ai_messages = [\n",
    "                m for m in response[\"messages\"]\n",
    "                if isinstance(m, AIMessage)\n",
    "            ]\n",
    "            #print(ai_messages)\n",
    "            output_list=[message.content for message in ai_messages]\n",
    "\n",
    "            #print(output_list)\n",
    "            output_list = [x for x in output_list if not ('think' in x or x == '')]\n",
    "            \n",
    "            try:\n",
    "                output_list = [safe_eval_with_dates(x) for x in output_list]\n",
    "                \n",
    "            except Exception as e:\n",
    "                e = f\"Error at transformation to dictionary: {e}\"\n",
    "                error_log(model=llm_model, error_message=e, ar_row_affected=row_ar, p_row_affected=row_p)\n",
    "                continue\n",
    "\n",
    "            non_empty = 0\n",
    "            empty = 0\n",
    "            for item in output_list:\n",
    "                if item:\n",
    "                    non_empty +=1\n",
    "                else:\n",
    "                    empty+=1\n",
    "\n",
    "            if non_empty >= 1: # We know that there has been at least one match\n",
    "                is_match = True\n",
    "                for output in output_list:\n",
    "                    try:\n",
    "                        if output is None: # Make sure only Non-Null rows are added\n",
    "                            pass\n",
    "                        else:\n",
    "                            updated_row = pd.DataFrame(output, index=[counter])\n",
    "                            updated_ar = pd.concat([updated_ar, updated_row], ignore_index=True)\n",
    "                            print(f\"Updated AR after match found: {updated_ar}\")\n",
    "                    except Exception as e:\n",
    "                        error_log(model=llm_model, error_message=e, ar_row_affected=row_ar, p_row_affected=row_p)\n",
    "\n",
    "            else:\n",
    "                pass\n",
    "           \n",
    "        if not is_match:\n",
    "            try:\n",
    "                old_ar_row = safe_eval_with_dates(row_ar)\n",
    "                updated_ar = pd.concat([updated_ar, old_ar_row.to_frame().T], ignore_index=True)\n",
    "                print(f\"Updated AR after no match: {updated_ar}\")\n",
    "            except Exception as e:\n",
    "                error_log(model=llm_model, error_message=e, ar_row_affected=row_ar, p_row_affected=row_p)\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    # Save updated DF to csv\n",
    "    updated_ar.dropna(axis=0, how='all', inplace=True)\n",
    "    updated_ar.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "    updated_ar.to_csv('updated_ar.csv', index=False)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf1d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Invoice Nr: 1/ 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching payments for invoice 1:   0%|          | 0/9 [00:00<?, ?it/s]/var/folders/4s/q4zndhns13bdmf7q1_8p3crc0000gn/T/ipykernel_2249/2948269516.py:105: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  updated_ar = pd.concat([updated_ar, updated_row], ignore_index=True)\n",
      "Matching payments for invoice 1:  11%|█         | 1/9 [02:11<17:35, 131.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated AR after match found:   invoice_number        date   customer_name customer_number   amount  \\\n",
      "0              1  2025-05-01  Planet Express           12038  50000.0   \n",
      "\n",
      "     due_date  payment payment_date payment_id  \n",
      "0  2025-05-02  25000.0   2025-01-31     948347  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching payments for invoice 1:  67%|██████▋   | 6/9 [08:44<03:56, 78.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated AR after match found:   invoice_number        date   customer_name customer_number   amount  \\\n",
      "0              1  2025-05-01  Planet Express           12038  50000.0   \n",
      "1              1  2025-05-01  Planet Express           12038  50000.0   \n",
      "\n",
      "     due_date  payment payment_date payment_id  \n",
      "0  2025-05-02  25000.0   2025-01-31     948347  \n",
      "1  2025-05-02  25000.0   2025-02-18     302947  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matching payments for invoice 1:  89%|████████▉ | 8/9 [11:36<01:23, 83.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated AR after match found:   invoice_number        date   customer_name customer_number   amount  \\\n",
      "0              1  2025-05-01  Planet Express           12038  50000.0   \n",
      "1              1  2025-05-01  Planet Express           12038  50000.0   \n",
      "2              1  2025-05-01  Planet Express           12038  50000.0   \n",
      "\n",
      "     due_date  payment payment_date payment_id  \n",
      "0  2025-05-02  25000.0   2025-01-31     948347  \n",
      "1  2025-05-02  25000.0   2025-02-18     302947  \n",
      "2  2025-05-02  76000.0   2025-01-03    2394759  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "turn_based_checker(accounts_receivable=accounts_receivables, payments=payments, generator_ar=generator_ar, generator_p=generator_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a149a93e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
